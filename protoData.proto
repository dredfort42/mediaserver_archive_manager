syntax = "proto3";
option optimize_for = LITE_RUNTIME;

package proto;

/***************************
 * System Digest Structure *
 ***************************/

/**
 * System Digest Entry
 * Topic settings:
 * - cleanup.policy=compact,delete \
 * - retention.ms=60000 \
 * - segment.ms=6000 \
 * - min.cleanable.dirty.ratio=0.01
 * ---
 * Kafka topic: digest
 * Key for Kafka message: ${ServiceUUID}
 */
message ProtoServiceDigest {
    /**
     * Service UUID (unique identifier)
     */
    string service_uuid = 1;

    /**
     * Service name (e.g., "mediaserver_manager", "rtsp_streamer", etc.)
     */
    string service_name = 2;

    /**
     * Service version
     */
    string service_version = 3;

    /**
     * Service status (reusing your existing codes)
     * 100 - Unknown
     * 101 - Starting
     * 102 - Ready
     * 103 - Degraded
     * 104 - Maintenance
     * 105 - Stopping
     * 106 - Stopped
     * 107 - Error
     */
    uint32 service_status_code = 4;

    /**
     * Service endpoints (host:port)
     */
    repeated string endpoints = 5;

    /**
     * Last heartbeat timestamp
     */
    uint64 last_heartbeat = 6; // Unix timestamp in milliseconds
}

/*******************************
 * Camera Properties Structure *
 *******************************/

/**
 * Camera Properties Entry
 * Topic settings:
 * - cleanup.policy=compact
 * - retention.ms=300000
 * - delete.retention.ms=300000
 * - segment.ms=30000
 * - min.cleanable.dirty.ratio=0.01
 * ---
 * Kafka topic: cameras
 * Key for Kafka message:  ${CameraUUID}
 */
message ProtoCamera {
    /**
     * Camera UUID (same as the message key)
     */
    string camera_uuid = 1;

    /** 
     * Main RTSP URL
     */
    string main_rtsp_url = 2;

    /**
     * Main connection type
     * OnDemand: 
     *      0 - standby
     *      1 - active
     * Permanent:
     *      8 - always on
     */
    uint32 main_connection_type = 3;

    /**
     * Sub RTSP URL
     */
    string sub_rtsp_url = 4;

    /**
     * Sub connection type
     * OnDemand: 
     *      0 - standby
     *      1 - active
     * Permanent:
     *      8 - always on
     */
    uint32 sub_connection_type = 5;

    /**
     * Status code
     * 0 - Status OFF
     * 1 - Status ON
     */
    uint32 status_code = 6;

    /**
     * Camera connector UUID
     * Instance that this camera is attached to.
     */
    string camera_connector_uuid = 7;

    /**
     * Archive retention days
     * Number of days to retain the archived footage.
     * 0 - means no archiving.
     */
    uint32 archive_retention_days = 8;
}

/******************************************
 * Camera Stream Parameters Structure *
 ******************************************/

/**
 * Camera Stream Parameters Entry
 * Topic settings:
 * - cleanup.policy=compact,delete \
 * - retention.ms=10000 \
 * - segment.ms=1000 \
 * - min.cleanable.dirty.ratio=0.01
 * ---
 * Kafka topic: camera_stream_parameters
 * Key for Kafka message: ${CameraUUID}
 */
message ProtoCameraStreamParameters {
    /**
     * State code
     * 0 - Not connected
     * 1 - Connecting
     * 2 - Connection established
     * 3 - Connection closed
     */
    uint32 camera_connection_state_code = 1;

    /**
     * Average bitrate of the video stream
     */
    uint32 video_avg_bitrate = 2;

    /**
     * Bitrate of the stream
     */
    uint32 video_bitrate = 3;

    /**
     * Frames per second
     */
    float video_fps = 4;

    /**
     * Width of video in pixels
     */
    int32 video_width = 5;

    /**
     * Height of video in pixels
     */
    int32 video_height = 6;
}

/**********************************
 * Camera Stream Codecs Structure *
 **********************************/

// Kafka topic: camera_stream_codecs
// Key for Kafka message: ${StreamType}_${MediaType}
// - StreamType: main/sub
// - MediaType: audio/video/data/subtitles/attachment
message ProtoCameraStreamCodecs {
    /**
     * General type of the encoded data.
     * Identifies the type of codec used for the media stream: 
     *      AVMEDIA_TYPE_VIDEO
     *      AVMEDIA_TYPE_AUDIO
     *      AVMEDIA_TYPE_DATA       ///< Opaque data information usually continuous
     *      AVMEDIA_TYPE_SUBTITLE
     *      AVMEDIA_TYPE_ATTACHMENT ///< Opaque data information usually sparse
     */
    int32 codec_type = 1;

    /**
     * Specific type of the encoded data (the codec used).
     * Identifies the codec used for the stream:
     *      video - H.264, H.265, etc.
     *      audio - AAC, MP3, etc.
     */
    int32 codec_id = 2; 

    /**
     * Additional information about the codec (corresponds to the AVI FOURCC).
     */
    uint32 codec_tag = 3;
    
    /**
     * Extra binary data needed for initializing the decoder, codec-dependent.
     */
    bytes extradata = 4;

    /**
     * Size of the extradata content in bytes.
     */
    int32 extradata_size = 5;

    /**
     * Format of the codec data:
     *      video - the pixel format, the value corresponds to enum AVPixelFormat.
     *      audio - the sample format, the value corresponds to enum AVSampleFormat.
     */ 
    int32 format = 6;

    /**
    * Name of the codec data format.
    */
    string format_name = 7;

    /**
    * The average bitrate of the encoded data (in bits per second).
    */ 
    uint64 bit_rate = 8;

    /**
     * The number of bits per sample in the codedwords.
     *
     * This is basically the bitrate per sample.
     * It is mandatory for a bunch of formats to actually decode them.
     * It's the number of bits for one sample in the actual coded bitstream.
     *
     * This could be for example 4 for ADPCM.
     * For PCM formats this matches bits_per_raw_sample.
     * Can be 0.
     */
    int32 bits_per_coded_sample = 9;

    /**
     * This is the number of valid bits in each output sample. 
     * If the sample format has more bits, the least significant bits are additional padding bits, which are always 0.
     * Use right shifts to reduce the sample to its actual size.
     * For example, audio formats with 24 bit samples will have bits_per_raw_sample set to 24, and format set to AV_SAMPLE_FMT_S32.
     * To get the original sample use "(int32_t)sample >> 8"."
     *
     * For ADPCM this might be 12 or 16 or similar.
     * Can be 0.
     */
    int32 bits_per_raw_sample = 10;

    /**
     * Codec-specific bitstream restrictions that the stream conforms to.
     */
    int32 profile = 11;
    int32 level = 12;


    /**
     * Video only.
     *
     * The dimensions of the video frame in pixels.
     */
    int32 width = 13;
    int32 height = 14;

    /**
     * Video only.
     *
     * The aspect ratio (width / height) which a single pixel should have when displayed.
     * When the aspect ratio is unknown / undefined, the numerator should be set to 0 (the denominator may have any value).
     *
     * @note sample_aspect_ratio = sample_aspect_ratio_num / sample_aspect_ratio_den
     */
    int32 sample_aspect_ratio_num = 15;
    int32 sample_aspect_ratio_den = 16;

     /**
     * Video only.
     *
     * Number of frames per second, for streams with constant frame durations.
     * Should be set to { 0, 1 } when some frames have differing durations or if the value is not known.
     *
     * @note framerate = framerate_num / framerate_den
     * This field correponds to values that are stored in codec-level headers and is typically overridden by container/transport-layer timestamps, when available. 
     * It should thus be used only as a last resort, when no higher-level timing information is available.
     */
    int32 framerate_num = 17;
    int32 framerate_den = 18;

    /**
     * Video only.
     *
     * The order of the fields in interlaced video.
     */
    int32 field_order = 19;
    
    /**
     * Video only.
     *
     * Additional colorspace characteristics.
     */
    int32 color_range = 20;
    int32 color_primaries = 21;
    int32 color_trc = 22;
    int32 color_space = 23;
    int32 chroma_location = 24;
    
    /**
     * Video only.
     *
     * Number of delayed frames.
     */
    int32 video_delay = 25;

    /**
     * Audio only.
     *
     * The channel layout and number of channels.
     *
     * Mandatory:
     *      Channel order used in this layout.
     *      Number of channels in this layout.
     */
    int32 ch_layout_order = 26;
    int32 ch_layout_nb_channels = 27;

    /**
     * Audio only.
     *
     * The number of audio samples per second.
     */
    int32 sample_rate = 28;

    /**
     * Audio only.
     *
     * The number of bytes per coded audio frame, required by some formats.
     *
     * Corresponds to nBlockAlign in WAVEFORMATEX.
     */
    int32 block_align = 29;
    
    /**
     * Audio only.
     *
     * Audio frame size, if known. Required by some formats to be static.
     */
    int32 frame_size = 30;
    
    /**
     * Audio only.
     *
     * The amount of padding (in samples) inserted by the encoder at the beginning of the audio. 
     * I.e. this number of leading decoded samples must be discarded by the caller to get the original audio without leading padding.
     */
    int32 initial_padding = 31;
    
    /**
     * Audio only.
     *
     * The amount of padding (in samples) appended by the encoder to the end of the audio.
     * I.e. this number of decoded samples must be discarded by the caller from the end of the stream to get the original audio without any trailing padding.
     */
    int32 trailing_padding = 32;
    
    /**
     * Audio only.
     *
     * Number of samples to skip after a discontinuity.
     */
    int32 seek_preroll = 33;

    /**
     * Stream index UUID.
     * This is a unique identifier for the stream index formed by the <camera UUID> + <_stream type> + <_media type>.
     */
     string stream_index_uuid = 34;
}

// /**************************************************************
//  * This structure describes the technical data of the camera. *
//  **************************************************************/
// // Kafka topic: kafka.topic.compact.minute.cameras.data
// // Key for Kafka message:  ${CameraUUID}
// message ProtoCameraData {
//     string camera_name = 1;
//     string camera_description = 2;
//     string camera_location = 3;
//     string camera_model = 4;
//     string camera_manufacturer = 5;
//     string camera_firmware_version = 6;
//     string camera_serial_number = 7;
//     // TODO: Add more camera data
// }

// /***********************************************
// * This structure describes the camera control. *
// ************************************************/
// // Kafka topic: ${CameraUUID}_control
// // Key for Kafka message: camera_control
// message ProtoCameraControl {
//     /**
//      * Control code
//      * 0 - Stop
//      * 1 - Start
//      * 2 - Restart
//      */
//     uint32 tmp_control_code = 1;
// }



/******************************************************************************************
 * This structure is typically exported by demuxers and then passed as input to decoders. *
 *                                                                                        *
 * For video it should typically contain one compressed frame.                            *
 * For audio it may contain several compressed frames.                                    *
 * Encoders are allowed to output empty packets, with no compressed data,                 *
 * containing only side data (e.g. to update some parameters at the end of encoding).     *
 ******************************************************************************************/
// Kafka topic: ${StreamUUID}_${StreamType}
// Key for Kafka message: ${MediaType}
// - StreamType: _main/_sub
// - MediaType: audio/video/data/subtitles/attachment
message ProtoPacket {
    /**
     * Time at which the decompressed packet will be presented to the user.
     * Can be AV_NOPTS_VALUE if it is not stored in the file.
     * pts MUST be larger or equal to dts as presentation cannot happen before decompression, unless one wants to view hex dumps.
     * Some formats misuse the terms dts and pts/cts to mean something different.
     * Such timestamps must be converted to true pts/dts before they are stored in AVPacket.
     */
    int64 pts = 1;

    /**
     * Decompression timestamp in AVStream->time_base units; the time at which
     * the packet is decompressed.
     * Can be AV_NOPTS_VALUE if it is not stored in the file.
     */
    int64 dts = 2;

    bytes data = 3;
    int32 size = 4;
    int32 stream_index = 5;

    /**
     * A combination of AV_PKT_FLAG values
     */
    int32 flags = 6;

    /**
     * Additional packet data that can be provided by the container.
     * Packet can contain several types of side information.
     * This structure stores auxiliary information for decoding, presenting, or otherwise processing the coded stream. It is typically exported by demuxers and encoders and can be fed to decoders and muxers either in a per packet basis, or as global side data (applying to the entire coded stream).
     */
    bytes side_data_data = 7;
    uint64 side_data_size = 8;
    int32 side_data_type = 9;
    int32 side_data_elems = 10;

    /**
     * Duration of this packet in AVStream->time_base units, 0 if unknown.
     * Equals next_pts - this_pts in presentation order.
     */
    int64 duration = 11;

    /**
     * Byte position in stream, -1 if unknown
     */
    int64 pos = 12;

    /**
     * Time base of the packet's timestamps.
     *
     * @note fime_base = time_base_num / time_base_den
     * By default ignored on input to decoders or muxers.
     */
    int32 time_base_num = 13;
    int32 time_base_den = 14;
}

// // // Kafka topic: kafka.topic.compact.offsets
// // // Key for Kafka message:  Camera UUID
// // message ProtoOffset {
// //     int64 timestamp = 1;
// //     int64 offset = 2;
// //     int32 folder = 3;
// //     int32 file = 4;
// // }

// // // Kafka topic: kafka.topic.compact.tasks
// // // Key for Kafka message:  Task UUID
// // message ProtoTask {
// //     string camera_uuid = 1;
// //     int32 start_file_folder = 2;
// //     int32 stop_file_folder = 3;
// //     int32 start_file_name = 4;
// //     int32 stop_file_name = 5;
// //     int64 start_offset = 6;
// //     int64 stop_offset = 7;
// //     bool is_relevant = 8;
// //     bool is_finished = 9;
// // }